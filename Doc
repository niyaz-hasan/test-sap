Nice — I’ll create a complete, ready-to-paste Confluence documentation blueprint for the repo you’re showing (the “Bayer CH Supply Chain Agents - CMO Purchase Order Automation POC”). It includes a page structure, page templates, recommended macros, sample content (converted from your README screenshots), a Page Properties metadata block you can reuse, a Lambdas table, architecture & workflow diagrams guidance, and a short checklist for publishing and maintenance.

You can paste the markdown below into a Confluence page (or convert to Confluence editor blocks). I label which parts are page content vs. templates vs. admin tasks so you can quickly build the documentation site.


---

Confluence documentation blueprint — CMO Purchase Order Automation (POC)

> Use this as the top-level documentation space for the project. Create a new Confluence space or a parent page named CMO Purchase Order Automation (POC) and add the child pages described below.




---

Top-level page: CMO Purchase Order Automation (POC)

Page Properties (metadata, for search & index)
Use a Page Properties macro with this table (paste into Confluence Page Properties):

Key	Value

Project	CMO Purchase Order Automation (POC)
Repo	bayer-int/smart-aws-bay-ch-px-ai-...
Owner	Supply Chain Agents / Niyaz-EDHHQ
Contact	supply-chain-dev@example.com
Status	Draft / Review / Published
Last updated	2025-11-07
Environments	dev / test / prod
Infra	Serverless (AWS SES, S3, Lambda, Step Functions, DynamoDB)
Diagram	documentation/ch.drawio (attached)
Tags / Labels	POC, AWS, serverless, CMO


Page body (overview)

Bayer CH Supply Chain Agents — CMO Purchase Order Automation POC

Short description
A proof-of-concept system that automates the manual processing of purchase order updates received from Contract Manufacturing Organizations (CMOs) via email.

Goal
Automate ingestion, extraction and processing of PO updates to reduce manual work and speed up updates into SAP.

Quick links

Architecture diagram (attached): documentation/ch.drawio

Code repo: https://github.com/bayer-int/smart-aws-bay-ch-px-ai-...

Runbook & On-call: (Link to runbook page)


Overview
This system automates the workflow that occurs when purchase order updates are received from CMOs:

1. Email Reception — Emails are received and stored in S3 via AWS SES.


2. Content Extraction — Email content (and attachments) is extracted and processed using AI (Amazon Bedrock).


3. Planning Data Retrieval — Relevant planning information is gathered and correlated with existing systems.


4. Criticality Assessment — Assess whether update is business-critical.


5. Automated Processing — Either update SAP automatically or escalate to human review.



(Add the Page Properties Report macro to list child pages with their metadata)


---

Child pages (suggested)

1. Architecture (detailed)


2. Workflow Details (expanded steps: Email Reception, Content Extraction, Planning Data, Criticality Check, Processing Decision)


3. Lambda Functions (function list, runtime, permissions)


4. Prerequisites & Setup (IAM, AWS accounts, Bedrock access)


5. Deploy & CI/CD (Terraform, GitHub Actions)


6. Runbook & Troubleshooting


7. Data & Security (S3 lifecycle, encryption, PII handling)


8. Documentation / Diagrams (drawio, sequence diagrams)


9. Change log / Release Notes




---

Template: Architecture page (paste and adapt)

Architecture

Summary
The system uses a serverless architecture on AWS consisting of:

AWS SES — Receives incoming emails from CMOs.

S3 — Stores email content and attachments.

EventBridge — Triggers processing when new emails arrive.

Lambda functions — Process different stages of the workflow.

Step Functions — Orchestrates the full workflow.

DynamoDB — Stores email metadata and processing state.

Amazon Bedrock — AI-powered content extraction (structured PO JSON).


Diagram
Attach documentation/ch.drawio or embed the draw.io macro. Also include a sequence diagram showing email → S3 → EventBridge → Lambda → Step Functions → DynamoDB → SAP / email escalation.

Detailed components

SES — inbound rule sets, receipt rule to drop to S3.

S3 bucket — naming convention, encryption (SSE-KMS), lifecycle (30 days raw, move to cold).

EventBridge — rule to detect new objects or SES event.

Lambda (email-reception) — extract metadata, write to DynamoDB, start state machine.

Bedrock (content-extraction) — returns structured JSON.

Step Functions — includes states: extract, planning-data, criticality-check, po-update/escalation.

DynamoDB — table schema (PK emailId, attributes: status, timestamps, extractedJson, retries).

SAP integration — connector details (API, authentication), if unavailable then email-based escalation.



---

Page: Workflow Details (paste)

Workflow Details

1. Email Reception

SES receives email and stores raw email in S3.

EventBridge or S3 event triggers the email-reception Lambda.

email-reception extracts metadata: from, to, subject, receivedTime, message-id.

Metadata saved to DynamoDB and Step Function invoked.


2. Content Extraction

Amazon Bedrock used to extract structured PO data from email body & attachments.

Attachments (PDF, XLSX) are pre-processed (OCR for images, text extraction).

Returns structured JSON containing PO number, line items, dates, quantities.


Note: Emails with secure attachments (Amazon secure-attach) may need human review.

3. Planning Data

Retrieve correlated planning information using internal APIs (list endpoints).

Add context: part master data, stock levels, lead times, related orders.


4. Criticality Check

Apply business rules to determine impact (e.g., if change affects > X quantity or critical supplier).

If critical → escalate email → escalation-email Lambda; if non-critical → proceed to po-update.


5. Processing Decision

Critical updates: Escalated via email to human reviewers.

Non-critical updates: Automatically update SAP via po-update function.



---

Page: Lambda Functions (ready table)

Use a Confluence table (or the Status macro for runtime / status) — example:

Function	Purpose	Runtime	Trigger	IAM roles

email-reception	Processes incoming emails and extracts metadata	Python 3.13	S3 / EventBridge	lambda-email-reception-role (S3 read, DynamoDB write, Step Functions start)
content-extraction	Extracts PO information using AI (Bedrock)	Python 3.13	Step Functions	lambda-bedrock-role (Bedrock invoke, S3 read)
planning-data	Retrieves planning data from internal APIs	Python 3.13	Step Functions	lambda-planning-role (VPC egress, SecretsManager read)
criticality-check	Assesses business criticality	Python 3.13	Step Functions	lambda-criticality-role
escalation-email	Sends escalation emails for critical updates	Python 3.13	Step Functions	lambda-ses-role (SES send)
po-update	Updates SAP system with PO changes	Python 3.13	Step Functions	lambda-sap-role (SecretsManager, API gateway)


Recommendations

Use least-privilege IAM roles.

Attach logging and tracing permissions (CloudWatch, X-Ray).

Add environment variables: ENV, LOG_LEVEL, S3_BUCKET, DYNAMODB_TABLE.



---

Page: Prerequisites & Setup

Accounts & access

AWS account(s): dev / test / prod

Bedrock access request: request form / ticket link

GitHub access: token stored in repo secrets


Infrastructure

Terraform state backend: S3 & DynamoDB (locking) — add backend file backend-smart-aws-dev.config.

Example var file: smart-aws-dev.tfvars (attach an example with non-sensitive values).


Secrets

Store credentials in AWS Secrets Manager (SAP credentials, API keys).

GitHub Actions: add GITHUB_TOKEN to secrets.


Local dev

Python 3.13 runtime for Lambdas.

Docker (for building Lambda packages).

Terraform CLI (v1.4+ recommended).



---

Page: Deploy & CI/CD

GitHub Actions (recommended workflow)
Create .github/workflows/deploy.yml with these important bits (short example based on your screenshot; adapt as needed):

name: Deploy

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        default: "dev"

permissions:
  contents: read
  id-token: write

env:
  TERRAFORM_VERSION: ${{ vars.TERRAFORM_VERSION || '1.4.6' }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  BACKEND_CONFIG: backend-smart-aws-${{ github.event.inputs.environment }}.config
  VAR_FILE: "smart-aws-${{ github.event.inputs.environment }}.tfvars"

jobs:
  terraform:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
      - name: Terraform Init
        run: terraform init -backend-config=${{ env.BACKEND_CONFIG }}
      - name: Terraform Plan
        run: terraform plan -var-file=${{ env.VAR_FILE }}
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve -var-file=${{ env.VAR_FILE }}

CI checks

tflint and terraform validate in PR checks.

Unit tests for Lambda functions (pytest).

Security scanning (Snyk / Trivy) for dependencies.



---

Page: Runbook & Troubleshooting

Monitoring

CloudWatch Logs for each Lambda.

X-Ray tracing enabled for Step Functions and Lambdas.

Alarms: failed invocations > threshold, Step Function failures, S3 errors.


Common issues & fixes

Bedrock extraction fails — check Bedrock quota & role permissions; re-run with debug logging.

SES inbound email not delivered to S3 — verify SES receipt rules and S3 bucket policy.

Lambda cannot access secret — check Secrets Manager ARN and IAM policy.


Escalation

On-call rotation: list persons and contact channels (email, pager).

If SAP update fails repeatedly → quarantine the PO in DynamoDB and notify supply chain ops.



---

Page: Data & Security

S3 encryption: SSE-KMS with CMK.

S3 bucket policy: restrict to SES, Lambda, internal IPs.

DynamoDB encryption and on-demand backups.

Retention policies for logs and S3 emails.

PII handling: redact or encrypt sensitive fields; log only non-PII or masked items.



---

Page: Diagrams & Documentation files

Attach documentation/ch.drawio and embed it on Architecture page.

Add sequence diagram (PlantUML) or Mermaid (if Confluence supports it) to show flow. Example mermaid snippet:


sequenceDiagram
  SES->>S3: Save email
  S3->>EventBridge: New object event
  EventBridge->>email-reception Lambda: Trigger
  email-reception->>DynamoDB: Save metadata
  email-reception->>StepFunctions: Start workflow
  StepFunctions->>content-extraction Lambda: call
  content-extraction->>Bedrock: extract
  Bedrock-->>content-extraction: JSON
  StepFunctions->>planning-data Lambda: call
  StepFunctions->>criticality-check Lambda: call
  alt non-critical
    StepFunctions->>po-update Lambda: update SAP
  else critical
    StepFunctions->>escalation-email Lambda: send email
  end


---

Page: Change log / Release notes

Keep a short changelog for each deployment: date, PR number, summary, author, environment deployed.



---

Confluence best-practice tips & macros to use

Page Properties / Page Properties Report — for metadata and cross-page listing.

Attachments macro — central place for diagrams and sample configs.

Expand macro — for long code samples (Terraform, GH Actions).

Children Display macro — to show child pages at top-level.

Status / Legend macros** — for state of pages (Draft/Published).

Include Page macro — to reuse common content (e.g., prerequisites).

Page permissions — restrict write access to owners & reviewers; grant read to stakeholders.

Labels — add serverless, aws, bedrock, sage, POC to pages for findability.



---

Sample content you can paste into the parent page (Markdown)

(If you prefer, copy the following as a ready content snippet for the top-level page.)

# Bayer CH Supply Chain Agents — CMO Purchase Order Automation POC

**Summary**
A proof-of-concept system that automates processing of purchase order updates received from CMOs via email.

**Workflow**
1. Email Reception — SES → S3
2. Content Extraction — Amazon Bedrock → structured JSON
3. Planning Data Retrieval — internal APIs
4. Criticality Assessment — business rules
5. Automated Processing — SAP update or escalation

**Quick Links**
- Architecture: (link)
- Workflow Details: (link)
- Lambda Functions: (link)
- Deploy & CI/CD: (link)
- Runbook: (link)


---

Checklist to publish the Confluence documentation

1. Create Space / Parent Page with title above.


2. Add Page Properties table to the parent page.


3. Create child pages following the names above (Architecture, Workflow, Lambdas, Deploy, Runbook).


4. Attach diagrams and config examples (drawio, tfvars with secrets removed).


5. Add labels: POC, serverless, AWS.


6. Set page permissions (editors: owners/dev team; viewers: stakeholders).


7. Add Page Properties Report to index key pages to show status and owners.


8. Add a short announcement in your team channel with link to space and request for review.




---

Short README-style text (for quick paste into Confluence or README)

Project: CMO Purchase Order Automation POC
Purpose: Automate ingestion and processing of PO updates sent by CMOs.
High-level architecture: SES → S3 → EventBridge → Lambda → Step Functions → DynamoDB → SAP / email.
Primary tech: AWS Serverless (SES, S3, Lambda, Step Functions), Amazon Bedrock, Terraform, GitHub Actions.


---

If you want, I can:

Convert the above into a filled Confluence page HTML/Storage format (if you paste a sample page or give me your Confluence flavor), or

Produce ready-to-upload draw.io XML for the architecture diagram, or

Create the GitHub Actions .yml and an example backend-*.config and smart-aws-dev.tfvars file (without secrets) for attaching to the Deploy page.


Which of those would you like next? 


Deploy workflow — Step‑by‑step (Confluence documentation)

Short description

This document explains the GitHub Actions workflow used to deploy the Consumer Health PoC environment (Terraform + lambda builds + AWS OIDC assume-role). It is written so it can be copied into Confluence as a single page and used as runbook + reference.


---

1. Purpose

Automate building artifacts (lambdas), initializing Terraform, planning and applying infrastructure changes.

Use GitHub OIDC to assume an AWS role for credentials (no long‑lived AWS keys stored in GitHub).

Allow manual trigger via workflow_dispatch and choose an environment to deploy (e.g. dev-...).



---

2. How to trigger

1. From GitHub Actions UI: open the workflow and click Run workflow (manual trigger). Choose an environment input value.


2. Can also be invoked by other workflows if merged into pipeline (not shown here).



The workflow uses workflow_dispatch with an environment input (required, has a default). The environment determines variable files and the Terraform backend file used during runs.


---

3. Prerequisites (what must be configured before using this workflow)

1. Secrets (Repository or Org-level)

GITHUB_TOKEN (GitHub provides automatically; used by some actions)

ORG_REPOS_INTERNAL_READ_ONLY (or a token that allows fetching private modules from an internal org repo) — used in git config so Terraform module sources that reference https://github.com/bayer-int will use this token.



2. Repository variables / secrets required by the workflow

FAWKES_AWS_DEPLOY_ROLE_ARN (stored as a variable referenced by vars.FAWKES_AWS_DEPLOY_ROLE_ARN in the workflow; this is the AWS role ARN the job will assume via OIDC).



3. Terraform backend files in repository (example: backend-smart-aws-dev.config) — the workflow sets env.BACKEND_CONFIG to point to the backend config file name.


4. TF var files (example: smart-aws-dev.tfvars) — the workflow sets env.VAR_FILE to the environment-specific tfvars file.


5. AWS OIDC trust relationship configured on the FAWKES_AWS_DEPLOY_ROLE_ARN to allow GitHub Actions to assume it. The role should grant the permissions Terraform needs (eg create/update EC2, ALB, RDS, Lambda, S3, etc.).


6. Module repository access: If Terraform modules are stored in a private GitHub org, the token ORG_REPOS_INTERNAL_READ_ONLY must have read access.




---

4. Workflow-level configuration (top of the YAML)

name: Deploy

on: workflow_dispatch.inputs.environment — manual trigger with environment input. The example default is dev-188509864883.

permissions: — grants contents: read and id-token: write. The id-token: write is required to use GitHub OIDC (aws-actions/configure-aws-credentials will exchange it for AWS credentials).

env: (global environment variables)

TERRAFORM_VERSION (value from vars.TERRAFORM_VERSION or fallback '1.13.3')

GITHUB_TOKEN (set to secrets.GITHUB_TOKEN)

BACKEND_CONFIG (example: backend-smart-aws-dev.config) — file name passed to terraform init --backend-config=

VAR_FILE (example: smart-aws-dev.tfvars) — var file used with terraform plan/apply



> Keep these env values updated when rolling out new Terraform versions or new environment names.




---

5. Jobs: deploy (high-level)

deploy is the single job in the provided workflow.

name: Deploy Consumer Health PoC

runs-on: [external-k8s-v2] — a custom runner label; replace with ubuntu-latest or your self-hosted runner label if necessary.

timeout-minutes: 20 — total job timeout (adjust for large Terraform runs).

environment: ${{ inputs.environment }} — ties GitHub environment protection rules to this run.

env: sets TF_PLAN_FILE to ${{ github.sha }}.tfplan (plan filename unique per commit sha).



---

6. Step-by-step breakdown (each step with purpose and example commands)

1. Setup git credentials so that Terraform modules can be fetched

run: git config --global url."https://token:${{ secrets.ORG_REPOS_INTERNAL_READ_ONLY }}@github.com/bayer-int".insteadOf https://github.com/bayer-int

Purpose: Rewrites Git URLs so that git/Terraform can fetch private modules from bayer-int using the token.



2. Install Python (actions/setup-python@v6)

uses: actions/setup-python@v6 with python-version: "3.13"

Purpose: Required by build tools (if just or other python scripts are used).



3. Install just (extractions/setup-just@v3)

Purpose: just is a task runner used in the repo (e.g. just build-lambdas). Installs tooling to run repo tasks.



4. Install uv (astral-sh/setup-uv@v4)

Purpose: uv (likely uvicorn helper or other tooling) — included in this setup. Keep if your build tasks need it.



5. Install Node (actions/setup-node@v4)

with: node-version: 22

Purpose: Required for frontend builds or any node-based toolchains used in lambdas or build steps.



6. Install Terraform (hashicorp/setup-terraform@v3)

with: terraform_version: 1.13.3 (or TERRAFORM_VERSION env variable)

Purpose: Make terraform CLI available in the runner.



7. Checkout repository (actions/checkout@v5)

Purpose: Get the code to the runner workspace.



8. Assume GitHub OIDC role (aws-actions/configure-aws-credentials@v5)

with:

aws-region: eu-central-1

role-to-assume: ${{ vars.FAWKES_AWS_DEPLOY_ROLE_ARN }}


Purpose: Exchange the GitHub Actions OIDC token for temporary AWS credentials so subsequent aws and terraform commands run under that role.



9. Verify that GitHub OIDC role was successfully assumed

run: aws sts get-caller-identity

Purpose: Print the assumed role identity to the job logs — useful to verify correct role.



10. Build Lambda functions

working-directory: lambdas

run: just build-lambdas

Purpose: Build packaging artifacts for lambdas (zip files, containers, etc.) which Terraform may later reference.



11. Terraform Init

working-directory: configuration

run: terraform init --backend-config=${{ env.BACKEND_CONFIG }}

Purpose: Initialize Terraform and configure remote backend (S3/DynamoDB or other) using the provided backend config file.



12. Terraform Plan

working-directory: configuration

run: terraform plan -out="${TF_PLAN_FILE}" -var-file=${{ env.VAR_FILE }} -input=false

Purpose: Create an execution plan and write it to TF_PLAN_FILE.



13. Terraform Apply

working-directory: configuration

run: terraform apply -input=false -auto-approve "${TF_PLAN_FILE}"

Purpose: Apply the previously created plan. -auto-approve used for non-interactive automation.




> Note: Depending on the environment, you may want to keep terraform apply manual (remove -auto-approve) or add an approval step.




---

7. Environment & GitHub Environment protections

The workflow sets environment: ${{ inputs.environment }} for the job. If you use GitHub Environments you can add protection rules (webhooks, required approvers, secrets) that gate deployment to some environment names (eg prod requires manual approval). Set the environment names to match the inputs.environment values you expect your team to choose.


---

8. Required repository variables and secrets (summary)

vars.FAWKES_AWS_DEPLOY_ROLE_ARN — repository variable (or org variable) storing the AWS role ARN.

secrets.ORG_REPOS_INTERNAL_READ_ONLY — token for fetching private Terraform modules.

secrets.GITHUB_TOKEN — usually available automatically.

backend-smart-aws-dev.config — backend config file checked into the repo (but be careful not to store sensitive secrets inside it)

smart-aws-dev.tfvars — terraform variable file (should NOT contain secrets; secrets should go to AWS Secrets Manager or terraform variables coming from secure stores).



---

9. Security considerations

Do not store long-lived AWS credentials in repository secrets. Use GitHub OIDC to assume roles (which this workflow does).

Token least-privilege: ORG_REPOS_INTERNAL_READ_ONLY should be read-only and restricted to the module repositories only.

Backend config: Backend files can contain bucket names / region / dynamodb table names but avoid embedding secrets like access keys.

Environment approvals: Protect prod environment with required reviewers in GitHub Environments.



---

10. Troubleshooting & common errors

aws sts get-caller-identity fails: Check permissions.id-token in workflow header (must be write) and check the OIDC trust policy on the role. Confirm role-to-assume ARN is correct.

Terraform module fetch fails: Confirm the git config --global url...insteadOf command uses a token with correct scope and that ORG_REPOS_INTERNAL_READ_ONLY is set in repository secrets.

Backend init fails: Confirm backend config filename in env.BACKEND_CONFIG is correct and that the S3 bucket/DynamoDB table for locking exist and the assumed role has access.

Timeouts: If timeout-minutes: 20 is too small for your plan/apply, increase it.

Provider permission errors: Ensure the assumed role has the IAM policies required by all Terraform providers (EC2, RDS, Lambda, S3, IAM, etc.).



---

11. Recommendations / Enhancements

1. Add explicit version variables: Use env.TERRAFORM_VERSION and reference it consistently in hashicorp/setup-terraform.


2. Split plan and apply: Add an approval step between terraform plan and terraform apply (GitHub Approvals or a manual workflow_dispatch for apply) for critical environments.


3. Store tfplan artifact: Upload the .tfplan as a workflow artifact so reviewers can inspect the plan before apply.


4. Lock runner label: If not using external-k8s-v2, use ubuntu-latest or document the self‑hosted runner requirements.


5. State drift / rollback: Add roll-back instructions and state restore process to the runbook.




---

12. Example: How to run (copyable)

1. In GitHub, go to Actions → Deploy


2. Click Run workflow


3. Select environment: dev-188509864883 (or your environment)


4. Click Run workflow



Watch logs for: aws sts get-caller-identity and terraform init output.


---

13. Change log / maintenance

v1 — Initial documentation based on provided workflow.

When changing Terraform version or role ARN, update this document and repository env/vars accordingly.



---

14. Appendix: Key YAML fragments referenced (for quick copy)

permissions:
  contents: read
  id-token: write

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        default: "dev-188509864883"

env:
  TERRAFORM_VERSION: ${{ vars.TERRAFORM_VERSION || '1.13.3' }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  BACKEND_CONFIG: backend-smart-aws-dev.config
  VAR_FILE: "smart-aws-dev.tfvars"

jobs:
  deploy:
    runs-on: [external-k8s-v2]
    environment: ${{ inputs.environment }}
    steps:
      - run: git config --global url."https://token:${{ secrets.ORG_REPOS_INTERNAL_READ_ONLY }}@github.com/bayer-int".insteadOf https://github.com/bayer-int
      - uses: actions/setup-python@v6
        with:
          python-version: "3.13"
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.3
      - uses: actions/checkout@v5
      - uses: aws-actions/configure-aws-credentials@v5
        with:
          aws-region: eu-central-1
          role-to-assume: ${{ vars.FAWKES_AWS_DEPLOY_ROLE_ARN }}
      - run: aws sts get-caller-identity
      - name: Terraform Init
        working-directory: configuration
        run: terraform init --backend-config=${{ env.BACKEND_CONFIG }}
      - name: Terraform Plan
        working-directory: configuration
        run: terraform plan -out="${TF_PLAN_FILE}" -var-file=${{ env.VAR_FILE }} -input=false
      - name: Terraform Apply
        working-directory: configuration
        run: terraform apply -input=false -auto-approve "${TF_PLAN_FILE}"


---

If you'd like, I can:

Convert this page into Confluence storage format or HTML for direct paste.

Add screenshots from the workflow YAML and annotate them.

Produce a short runbook checklist tile for Confluence (checkboxes for pre-deploy steps).


Which of these would you like next?

Done — I created a Confluence-ready step-by-step document for that GitHub Actions deploy workflow and saved it as a page you can edit.

If you want, I can now:

Convert it to Confluence storage format (HTML/XML) for direct import,

Add annotated screenshots of the YAML steps,

Produce a concise pre-deploy checklist (checkbox style) for the Confluence page.


Which would you like next?

while read -r j; do aws glue get-job --job-name "$j" --query "Job.{Name:Name,WorkerType:WorkerType,NumberOfWorkers:NumberOfWorkers,MaxCapacity:MaxCapacity}" --output json || echo "{\"Name\":\"$j\",\"error\":\"not found\"}"; done < jobs.txt > jobs-capacity.json

